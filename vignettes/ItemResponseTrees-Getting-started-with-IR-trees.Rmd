---
title: "Getting started with IR-trees"
output: 
    rmarkdown::html_vignette:
        readme: true
        self_contained: true
vignette: >
  %\VignetteIndexEntry{Getting started with IR-trees}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
options(tibble.print_min = 10, tibble.print_max = 20, pillar.min_title_chars = 16)
```

[![R build status](https://github.com/hplieninger/ItemResponseTrees/workflows/R-CMD-check/badge.svg)](https://github.com/hplieninger/ItemResponseTrees/actions)
[![codecov](https://codecov.io/gh/hplieninger/ItemResponseTrees/branch/master/graph/badge.svg)](https://codecov.io/gh/hplieninger/ItemResponseTrees)
[![Say Thanks!](https://img.shields.io/badge/Say%20Thanks-!-1EAEDB.svg)](https://saythanks.io/to/plieninger@uni-mannheim.de)

## ItemResponseTrees

ItemResponseTrees is an R package that allows to fit IR-tree models in mirt, Mplus, or TAM.
If you're unfamiliar with IR-trees, the paper of [Böckenholt (2012)](https://dx.doi.org/10.1037/a0028111) is a good starting point.
If you're familiar with the class of IR-tree models, this tutorial will get you started.
The package automates some of the hassle of IR-tree modeling by means of a consistent syntax.
This allows new users to quickly adopt this model class, and this allows experienced users to fit many complex models effortlessly.

The package can be installed as follows:

```{r, eval = FALSE}
install.packages("remotes")
remotes::install_github("hplieninger/ItemResponseTrees")
```

## Example Data

Herein, an illustrative example will be shown using a popular IR-tree model for 5-point items (Böckenholt, 2012).
The model is applied to a Big Five data set from Jackson (2012), more precisely to seven conscientiousness items.

```{r data, message = FALSE}
library("ItemResponseTrees")

data("jackson")

set.seed(9701)
df1 <- jackson[sample(nrow(jackson), 321), paste0("E", 1:9)]
df1
```

## Defining the Model

The model is defined by the following tree diagram.
The model equations can be directly derived from the diagram:
The probability for a specific category is given by multiplying all parameters along the branch that lead to that category (see also Böckenholt, 2012; Plieninger & Heck, 2018).
For example, the branch leading to Category 5 is comprised of the parameters (1-*m*), *t*, and *e*.
The resulting five equations are shown in the right part of the figure.

```{r, out.width="80%", echo = FALSE, out.extra='style="border:0px;display: block;  margin-left: auto; margin-right: auto;"'}

if (!isTRUE(all.equal(tools::md5sum("tools/ecn-model.png"),
                      tools::md5sum("../tools/ecn-model.png"), check.attributes = FALSE))) {
    invisible(file.copy("../tools/ecn-model.png", "tools/ecn-model.png",
                        overwrite = TRUE))
}

knitr::include_graphics("tools/ecn-model.png")
```

In the ItemResponseTrees package, a model is defined using a specific syntax that consists mainly of three parts.

1. `Equations:` Herein, the model equation for each response category is listed in the format `cat = p1 * (1-p2)`, where `cat` is one of the observed responses (e.g., 1, ..., 5). Furthermore, `p1` is a freely chosen parameter label, and I've chosen `t`, `e`, and `m` below corresponding to the diagram above.
2. `IRT:` The parameters in the `Equations` (and also those in the figure above) actually correspond to latent variables of an IRT model.
These latent variables are measured using a number of items/variables, and this is specified in this section using the same parameter labels as in `Equations`.  
The format for this section is highly similar to the MODEL statement in Mplus: a semicolon is used after each definition; loadings (discrimination parameters) can be fixed using `@`.
The syntax below fixes all loadings corresponding to dimensions *e* and *m* to 1 corresponding to a 1PL or Rasch model, whereas all loadings corresponding to dimension *t* are freely estimated (i.e., 2PL-structure).
3. `Class:` Can be either `Tree` for an IR-tree model or `GRM` for a graded response model.

```{r template, eval = FALSE}
# Use irtree_create_template() to create a model-string template:
irtree_create_template(df1)
```

In the following, the model string for the desired IR-tree model for the nine items is specified and saved as `m1`.

```{r model-tree}
m1 <- "
# IR-tree model for 5-point items (Böckenholt, 2012)

IRT:
t  BY  E1,   E2,   E3,   E4,   E5,   E6,   E7,   E8,   E9;
e  BY  E1@1, E2@1, E3@1, E4@1, E5@1, E6@1, E7@1, E8@1, E9@1;
m  BY  E1@1, E2@1, E3@1, E4@1, E5@1, E6@1, E7@1, E8@1, E9@1;

Equations:
1 = (1-m)*(1-t)*e
2 = (1-m)*(1-t)*(1-e)
3 = m
4 = (1-m)*t*(1-e)
5 = (1-m)*t*e

Class:
Tree
"
```

In case of a graded response model, only two sections need to be specified.

```{r model-grm}
m2 <- "
# Graded response model

IRT:
t  BY  E1,   E2,   E3,   E4,   E5,   E6,   E7,   E8,   E9;

Class:
GRM
"
```

Subsequently, the model strings `m1` and `m2` need to be parsed by `irtree_model()`. 
The resulting objects `model1` and `model2` of class `irtree_model` contain all the necessary information for fitting the model.
Furthermore, one may inspect specific elements, for example, the pseudoitems contained in the mapping matrix.

Further information on creating model strings is provided in `?irtree_model()`.

```{r}
model1 <- irtree_model(m1)
model2 <- irtree_model(m2)

model1$mapping_matrix
```


## Fitting the model

The ItemResponseTrees package provides wrapper functions for Mplus (via the [MplusAutomation](https://cran.r-project.org/package=MplusAutomation) package), for the [mirt](https://cran.r-project.org/package=mirt) package, and for the [TAM](https://cran.r-project.org/package=TAM) package.
To fit a model, the model string as defined above has to be converted into an object of class `irtree_model` using the function `irtree_model()`.
Then, the model can be `fit()` as follows:

```{r fit, cache = TRUE, warning = FALSE, message = FALSE}
# mirt can be used with an EM algorithm (the default) or, for example, with the
# MH-RM algorithm, which seems a little bit faster here.
# See ?mirt::mirt for details.
ctrl <- control_mirt(method = "MHRM")

fit1 <- fit(model1, data = df1, engine = "mirt", control = ctrl)
fit2 <- fit(model2, data = df1, engine = "mirt", control = ctrl)
```

## Results

### Model Fit

Information about model fit is obtained via `glance()`.
As seen below, the IR-tree model has 41 freely estimated parameters (3 x 9 thresholds + 9 loadings + 2 variances + 3 covariances).
The GRM has 45 estimated parameters (4 x 9 thresholds + 9 loadings).
(Of course, this comparison is a little bit unfair, because the IR-tree model is much more flexible in terms of dimensionality/"random effects" even though it is less flexible with respect to the thresholds/"fixed effects".)

For the present data, the IR-tree model slightly outperforms the GRM according to AIC and BIC, and thus one may conclude that response styles are present in these data.

```{r}
glance(fit1)

rbind(glance(fit1), glance(fit2))
```

### Parameter Estimates

The parameter estimates are obtained via `tidy()`.
For the IR-tree model, this returns a tibble with 66 rows (pertaining to the fixed and estimated parameters).
Below, the nine threshold/difficulty parameters `t_E*.d` pertaining to parameter *t* are shown plus the threshold of pseudoitem `e_E1`.
<!-- The loadings pertaining to parameter *e* (`e_*.a2`) and *m* (`m_*.a3`) were fixed to one and thus no standard error is returned for these. -->
The latent correlations are shown below as well, and these show the typical pattern of a negative correlation between *e* and *m*.

```{r}
tidy(fit1, par_type = "difficulty")

tail(tidy(fit1, par_type = "difficulty"), 3)
```

### Factor scores

The factor scores or person parameter estimates are obtained via `augment()`.
This returns a tibble comprised of the data set and the factor scores (plus respective standard errors) for the three dimensions *t* (F1), *e* (F2), and *m* (F3).^[The order corresponds to the order of appearance in the section `IRT` of the model string.]

The correlation of the scores for the target trait (extraversion in this case) between the IR-tree model and the GRM indicates that the models differ in this respect even though not drastically.

```{r augment, cache = TRUE}
augment(fit1)

cor(augment(fit1)$.fittedF1, augment(fit2)$.fittedF1)
```
